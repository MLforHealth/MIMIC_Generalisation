{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>training_demo</h1>\n",
    "\n",
    "<p>Overview - extract some data and examine how the physiometrics which are measured affect the prediction accuracy</p>\n",
    "<ol>\n",
    "    <li><a href='#mortality'>Mortality Results</a></li>\n",
    "    <li><a href='#los'>Length of Stay Results</a></li>\n",
    "    <li><a href='#sensitive'>Sensitive Group Results</a></li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# import the dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import psycopg2\n",
    "import pandas.io.sql as psql\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso, LinearRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from IPython.display import display\n",
    "\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from utils import AUC_GH\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Load the the modules from AUC_GH</h2>\n",
    "\n",
    "in general:\n",
    "\n",
    "AUC_GH.main():\n",
    "Inputs:\n",
    "<ul>\n",
    "    <li>random_seed (int) (default=None): control the random seed of the data split</li>\n",
    "    <li>max_time (int) (default=24): maximum amount of time to flatten out for prediction</li>\n",
    "    <li>test_size (float) (default=0.2): the default test train split</li>\n",
    "    <li>level (str) (default='Level2'): choose which embedding to use</li>\n",
    "    <li>target (str) (default='mort_icu'): Select the task for clinical prediction</li>\n",
    "    <li>prefix (str):a prefix to differentiate the text file which is saving these experiments.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> How well does the data persist from year to year?</h2>\n",
    "\n",
    "Read the years datafrom the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of text files\n",
    "text_files=glob.glob('utils/AUC*.txt')\n",
    "\n",
    "#make a dataframe of all the data\n",
    "#column headings: modeltype, level, representation, train_type, measurement\n",
    "#index=random_seed\n",
    "columns=[]\n",
    "for target in ['mort_icu', 'los_3']:\n",
    "    for model in ['rf', 'lr', 'svm', 'rbf-svm', 'knn', 'mlp', 'lstm', 'grud']:\n",
    "        for representation in ['Level2', 'itemid', 'pca', 'umap', 'autoencoder', 'nlp']:\n",
    "            for train_type in ['GH', 'Rolling', 'Rolling_limited']:\n",
    "                for measurement in ['AUC', 'APR', 'Acc', 'F1', 'date_trained']:\n",
    "                    columns.append((target,model, representation, train_type, measurement))\n",
    "index=[(item1, item2) for item1 in range(5) for item2 in np.arange(2001, 2013)]\n",
    "a = np.empty((len(index),len(columns)))\n",
    "a = np.nan\n",
    "data=a\n",
    "ind=pd.MultiIndex.from_tuples(index, names=('seed', 'year'))\n",
    "cols=pd.MultiIndex.from_tuples(columns, names=('target', 'model', 'representation', 'train_type', 'measurement'))\n",
    "df=pd.DataFrame( index=ind, columns=cols) # 4 columns, 2 indices\n",
    "\n",
    "# print(cols)\n",
    "\n",
    "cols=pd.MultiIndex.from_tuples(set([(item[0], item[1], item[2], item[4]) for item in columns]), names=('target', 'model', 'representation', 'measurement'))\n",
    "empty_data=np.empty((5,len(set([(item[0], item[1], item[2], item[4]) for item in columns]))))\n",
    "empty_data[:] = np.nan\n",
    "no_years_df=pd.DataFrame(data=empty_data, columns=cols)\n",
    "\n",
    "\n",
    "for target in ['mort_icu', 'los_3']:\n",
    "    print(target)\n",
    "    for modeltype in tqdm(['rf', 'lr', 'svm', 'rbf-svm', 'knn', 'mlp', 'lstm', 'grud']):\n",
    "\n",
    "        for level in ['Level2', 'itemid', 'nlp']:\n",
    "            for representation_in in ['raw', 'pca', 'umap', 'autoencoder']:\n",
    "                if (level!='itemid')&(representation_in!='raw'):\n",
    "                    continue\n",
    "                for text_file in sorted(text_files):\n",
    "                    if target not in text_file:\n",
    "                        continue\n",
    "                    if (modeltype.upper() in text_file)&(level in text_file)&(representation_in in text_file):\n",
    "                        train_type=text_file.split(\"AUC_\")[-1].split('-style')[0]\n",
    "\n",
    "                        \n",
    "                        assert(train_type in ['GH', 'Rolling', 'Rolling_limited', 'no_years'])\n",
    "                        seed=text_file.split(\"seed-\")[-1].split('_test-')[0]\n",
    "                        if seed ==5:\n",
    "                            continue\n",
    "                        if train_type=='no_years':\n",
    "                            seed=text_file.split(\"seed-\")[-1].split('_target')[0]\n",
    "                        if 'raw' in text_file:\n",
    "                            representation=copy.deepcopy(level)\n",
    "                        else:\n",
    "                            representation=copy.deepcopy(representation_in)\n",
    "\n",
    "                        with open(text_file, 'rb') as f:\n",
    "                            all_lines=f.readlines()\n",
    "                        try:\n",
    "                            df.loc[(int(seed), slice(None)), (target, modeltype, representation, train_type, 'date_trained')]=os.path.getmtime(text_file)\n",
    "                        except:\n",
    "                            print(os.path.getmtime(text_file), int(seed))\n",
    "                        for measurement in ['AUC', 'APR', 'Acc', 'F1']:\n",
    "                            lines=[line.decode() for line in all_lines if measurement in line.decode()]\n",
    "                            for line in lines:\n",
    "                                if train_type!='no_years':\n",
    "                                    for year in np.arange(2001, 2013):\n",
    "                                        if (str(year) in line.split(\",\")[1]):\n",
    "                                            value=float(line.split(\",\")[-1])\n",
    "                                            df.loc[(int(seed), int(year)), (target, modeltype, representation, train_type, measurement)]=value\n",
    "\n",
    "                            if train_type=='no_years':\n",
    "                                for line in lines:\n",
    "                                    value= float(line.split(\",\")[-1])\n",
    "                                    seed= int(line.split(\",\")[1])\n",
    "                                    no_years_df.loc[int(seed), (target, modeltype, representation, measurement)]=value\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# display(df.head(5))\n",
    "# display(no_years_df.head(5))\n",
    "\n",
    "df=df.apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric='AUC'\n",
    "averaged_df=df.groupby('year').mean().loc[:, (slice(None), slice(None), slice(None), slice(None), metric)]\n",
    "ste_df=df.groupby('year').std().loc[:, (slice(None), slice(None), slice(None), slice(None), metric)]/np.sqrt(5)\n",
    "averaged_static_df=no_years_df.mean()\n",
    "\n",
    "averaged_df.columns = averaged_df.columns.droplevel(-1)\n",
    "ste_df.columns = ste_df.columns.droplevel(-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Remaining files to train</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "untrained=[]\n",
    "for target in ['mort_icu', 'los_3']:\n",
    "    for train_type in ['Rolling', 'Rolling_limited', 'GH']:\n",
    "        for modeltype in ['rf', 'lr', 'lstm', 'grud']:\n",
    "            for level in ['Level2', 'itemid', 'nlp']:\n",
    "                for representation in ['raw', 'pca']:\n",
    "                    if (modeltype=='grud')&(representation !='raw'):\n",
    "                        continue\n",
    "                    if (level!='itemid')&(representation !='raw'):\n",
    "                        continue\n",
    "                    rep_level=copy.deepcopy(representation)\n",
    "                    if rep_level=='raw':\n",
    "                        rep_level=copy.deepcopy(level)\n",
    "                    for seed in range(5):\n",
    "                        target_file='utils/AUC_{}-style_{}_{}_Simple_{}_seed-{}_test-size-02_target={}.txt'.format(train_type, modeltype.upper(), representation, level, seed, target)\n",
    "                        \n",
    "                        if np.isnan(df.loc[(seed, 2011), (target,modeltype, rep_level, train_type, 'AUC')]):\n",
    "                            # join params and check if it is in textfiles\n",
    "                            \n",
    "                            if target_file in text_files:\n",
    "                                print(\"\\n trouble with \", target_file)\n",
    "                                print(\"\\n\")\n",
    "                                \n",
    "                            train_type_output=train_type.lower()\n",
    "                            if train_type_output == 'gh':\n",
    "                                train_type_output='2001-2002'\n",
    "                            \n",
    "                            print('python AUC_GH.py --target {} --train_type {} --modeltype {} --level {} --representation {} --random_seed {} --data_dir /scratch/bnestor/mimic-years;\\\\'.format(\\\n",
    "                                                                                        target, train_type_output, modeltype, level, representation, seed))\n",
    "                            untrained.append('python AUC_GH.py --target {} --train_type {} --modeltype {} --level {} --representation {} --random_seed {} --data_dir /scratch/bnestor/mimic-years;\\\\'.format(\\\n",
    "                                                                                        target, train_type_output, modeltype, level, representation, seed))\n",
    "#                         for textfile in textfiles:\n",
    "#                             all(item in text_file for item in [target, train_type, modeltype, level, representation])\n",
    "print(len(untrained))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Plots for Mortality</h2>\n",
    "<a id=mortality></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block of code produces subplots with shared x axes and y axes in the range of 0.5-1 for all AUCs on the task of mortality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_STYLES    = ['GH', 'Rolling_limited', 'Rolling']\n",
    "REPRESENTATIONS = ['itemid', 'pca', 'nlp', 'Level2']\n",
    "MODEL_TYPES     = ['rf', 'lr', 'lstm', 'grud']\n",
    "\n",
    "NAMES = {\n",
    "    'GH': '2001-2002',\n",
    "    'Rolling': 'Full History',\n",
    "    'Rolling_limited': 'Prior Year',\n",
    "    'itemid': 'Raw',\n",
    "    'pca': 'PCA',\n",
    "    'umap': 'UMAP',\n",
    "    'nlp': 'CUI Code Spanning',\n",
    "    'Level2': 'Clinical Aggregations',\n",
    "    'rf': 'Random Forest',\n",
    "    'lr': 'Logistic Regression',\n",
    "    'lstm': 'LSTM',\n",
    "    'grud': 'GRU-D'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for ticks\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter, AutoMinorLocator)\n",
    "minorLocator = MultipleLocator(1)\n",
    "\n",
    "target='mort_icu'\n",
    "\n",
    "fig=plt.figure(dpi=200)\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    len(TRAIN_STYLES), len(MODEL_TYPES), sharex=True, sharey=True, figsize=(20, 7), dpi=160, facecolor='w', edgecolor='k'\n",
    ")\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.1)\n",
    "\n",
    "orig_ticks=axs[0,0].get_yticks()\n",
    "print(orig_ticks)\n",
    "for i in range(len(TRAIN_STYLES)):\n",
    "    for j in range(len(MODEL_TYPES)):\n",
    "        axs[i,j].set_yticks([])\n",
    "\n",
    "\n",
    "\n",
    "for i, train_style in enumerate(TRAIN_STYLES):\n",
    "    for j, representation in enumerate(REPRESENTATIONS):\n",
    "#         for modeltype in ['rf', 'lr', 'svm', 'rbf-svm', 'knn', 'mlp', 'lstm', 'gru']:\n",
    "        colours = iter(['#006BA4', '#FF800E', '#ABABAB', '#595959', '#5F9ED1', '#C85200', '#898989', '#A2C8EC', '#FFBC79', '#CFCFCF'])\n",
    "#         colours=iter(['#648FFF', '#785EF0', '#DC267F', '#FE6100', '#FFB000']) #IBM\n",
    "        colours=iter(['#648FFF',  '#DC267F', '#FE6100', '#FFB000', '#785EF0']) #IBM\n",
    "#         colours=iter(['#332288', '#117733', '#44AA99', '#88CCEE', '#DDCC77', '#CC6677', '#AA4499', '#882255'])#tol\n",
    "#         colours=iter(['#332288', '#44AA99', '#CC6677', '#882255'])\n",
    "        markers=iter(['solid', 'dashed','dashdot','dotted'])\n",
    "        markers=iter(['solid', 'solid','solid','solid'])\n",
    "        for modeltype in MODEL_TYPES:\n",
    "            years=averaged_df.index.tolist()\n",
    "            years=[year for year in years if year not in {2001, 2002}]\n",
    "\n",
    "\n",
    "\n",
    "            axs[i,j].set_yticks([0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "            axs[i,j].set_xticks([2003, 2005, 2007, 2009, 2011, 2013])\n",
    "#             if i == 2: axs[i,j].set_xticklabels([2003, 2005, 2007, 2009, 2011, 2013])\n",
    "            axs[i,j].set_xlim(2002.5, 2013.5)\n",
    "            axs[i,j].set_ylim([0.5,1.0])\n",
    "            axs[i,j].xaxis.set_minor_locator(minorLocator)\n",
    "            axs[i,j].axvspan(2008, 2009, facecolor='#d1d1d1', alpha=0.6, label=\"CareVue → MetaVision\")\n",
    "            try:\n",
    "                means=averaged_df.loc[years, (target, modeltype, representation, train_style)].values\n",
    "                err=ste_df.loc[years, (target, modeltype, representation, train_style)].values\n",
    "#                 print(years, means, err)\n",
    "                c=next(colours)\n",
    "                gh_plot=axs[i,j].errorbar(\n",
    "                    [x + 0.5 for x in years],means,err, label=NAMES[modeltype], linewidth=4, color=c, linestyle=next(markers),\n",
    "                )\n",
    "                \n",
    "            except:\n",
    "                pass\n",
    "#             # Save just the portion _inside_ the second axis's boundaries\n",
    "            save_name=os.path.abspath(\"mort_icu-{}-{}.png\".format(train_style, representation))\n",
    "            bbox = axs[i,j].get_tightbbox(fig.canvas.get_renderer())\n",
    "            fig.savefig(save_name,bbox_inches=bbox.transformed(fig.dpi_scale_trans.inverted()))\n",
    "            if (i==0)&(j==0):\n",
    "                handles=0\n",
    "\n",
    "\n",
    "                \n",
    "for i, train_style in enumerate(TRAIN_STYLES):\n",
    "    for j, representation in enumerate(REPRESENTATIONS):\n",
    "        axs[i,j].set_yticks([0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "        axs[i,j].yaxis.grid() # horizontal lines\n",
    "\n",
    "        \n",
    "            \n",
    "        axs[i,j].tick_params(labelsize=13)\n",
    "        if i==0: axs[i,j].set_title(NAMES[representation], fontsize=22)\n",
    "        if j==0: axs[i,j].set_ylabel(NAMES[train_style], fontsize=22)\n",
    "    \n",
    "handles, labels = axs[1,1].get_legend_handles_labels()\n",
    "ax = fig.add_axes([0.8, 0.9, 0.1, 0.45])\n",
    "ax.set_axis_off()\n",
    "\n",
    "fig.legend(handles[3:], labels[3:], loc=\"upper right\", borderaxespad=0.2, bbox_to_anchor=(0.81,1.27), fontsize=22)\n",
    "fig.suptitle('Mortality AUROC vs. Time, by Model & Representation', fontsize=24)\n",
    "\n",
    "\n",
    "plt.savefig('mort_icu-results.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tabular mortality results\n",
    "metric='AUC'\n",
    "# metric='APR'\n",
    "target='mort_icu'\n",
    "target='los_3'\n",
    "\n",
    "idx=pd.IndexSlice\n",
    "\n",
    "# display(df.loc[idx[:, list(range(2002,2013))], :].head(5))\n",
    "# display(no_years_df.head(5))\n",
    "print('For year agnostic performance')\n",
    "print(metric, target)\n",
    "print(\"\\n\")\n",
    "\n",
    "for model in ['lr', 'rf', 'lstm', 'grud']:\n",
    "    all_scores=no_years_df.loc[:, idx[target, model, 'itemid', metric]].values\n",
    "    m_raw=np.mean(all_scores)\n",
    "    s_raw=np.std(all_scores)\n",
    "    all_scores=no_years_df.loc[:, idx[target, model, 'pca', metric]].values\n",
    "    m_pca=np.mean(all_scores)\n",
    "    s_pca=np.std(all_scores)\n",
    "    all_scores=no_years_df.loc[:, idx[target, model, 'nlp', metric]].values\n",
    "    m_nlp=np.mean(all_scores)\n",
    "    s_nlp=np.std(all_scores)\n",
    "    all_scores=no_years_df.loc[:, idx[target, model, 'Level2', metric]].values\n",
    "    m_clin=np.mean(all_scores)\n",
    "    s_clin=np.std(all_scores)\n",
    "    print('{} & ${:.2f} \\\\pm {:.2f}$ & ${:.2f} \\\\pm {:.2f}$ & ${:.2f} \\\\pm {:.2f}$ & ${:.2f} \\\\pm {:.2f}$ \\\\\\\\'.format(model.upper(), m_raw, s_raw, m_pca, s_pca, m_nlp, s_nlp, m_clin, s_clin))\n",
    "                               \n",
    "print(\"\\n\")\n",
    "print('For Rolling average performance/year')\n",
    "print(\"\\n\")\n",
    "for model in ['lr', 'rf', 'lstm', 'grud']:\n",
    "    all_scores=df.loc[idx[:, list(range(2002,2013))], :].groupby('year').mean().loc[:, (target, model, 'itemid', 'Rolling', metric)].values\n",
    "    m_raw=np.mean(all_scores)\n",
    "    s_raw=np.std(all_scores)\n",
    "    all_scores=df.loc[idx[:, list(range(2002,2013))], :].groupby('year').mean().loc[:, (target, model, 'pca', 'Rolling', metric)].values\n",
    "    m_pca=np.mean(all_scores)\n",
    "    s_pca=np.std(all_scores)\n",
    "    all_scores=df.loc[idx[:, list(range(2002,2013))], :].groupby('year').mean().loc[:, (target, model, 'nlp', 'Rolling', metric)].values\n",
    "    m_nlp=np.mean(all_scores)\n",
    "    s_nlp=np.std(all_scores)\n",
    "    all_scores=df.loc[idx[:, list(range(2002,2013))], :].groupby('year').mean().loc[:, (target, model, 'Level2', 'Rolling', metric)].values\n",
    "    m_clin=np.mean(all_scores)\n",
    "    s_clin=np.std(all_scores)\n",
    "    \n",
    "    print('{} & ${:.2f} \\\\pm {:.2f}$ & ${:.2f} \\\\pm {:.2f}$ & ${:.2f} \\\\pm {:.2f}$ & ${:.2f} \\\\pm {:.2f}$ \\\\\\\\'.format(model.upper(), m_raw, s_raw, m_pca, s_pca, m_nlp, s_nlp, m_clin, s_clin))\n",
    "    \n",
    "#     m_raw_no=no_years_df\n",
    "#     max_loss_raw, max_loss_clinical=0.24, 0.32,\n",
    "#     print('{} & ${:.2f} \\\\pm {:.2f}$ \\& ${:.2f} \\\\pm {:.2f}$ \\&\\&\\& {:.2f} & {:.2f} \\\\\\\\'.format(model.upper(), m_raw,s_raw, m_clin, s_clin, max_loss_raw, max_loss_clinical))\n",
    "\n",
    "print('\\n For Average AUROC rolling and max delta AUROC \\n')\n",
    "\n",
    "for model in ['lr', 'rf', 'lstm', 'grud']:\n",
    "    all_scores=averaged_df.loc[list(range(2002,2013)), :].groupby('year').mean().loc[:, (target, model, 'itemid', 'Rolling')].values\n",
    "    m_raw=np.mean(all_scores)\n",
    "    s_raw=np.std(all_scores)\n",
    "    all_scores=averaged_df.loc[list(range(2002,2013)), :].groupby('year').mean().loc[:, (target, model, 'nlp', 'Rolling')].values\n",
    "    m_nlp=np.mean(all_scores)\n",
    "    s_nlp=np.std(all_scores)\n",
    "    all_scores=averaged_df.loc[list(range(2002,2013)), :].groupby('year').mean().loc[:, (target, model, 'Level2', 'Rolling')].values\n",
    "    m_clin=np.mean(all_scores)\n",
    "    s_clin=np.std(all_scores)\n",
    "    \n",
    "    # max felta AUROC\n",
    "    all_scores=averaged_df.loc[[2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012], (target, model, 'itemid', 'Rolling')]-averaged_df.loc[2002, (target, model, 'itemid', 'Rolling')]\n",
    "    md_raw=np.min(all_scores)\n",
    "#     all_scores=np.asarray(all_scores)\n",
    "#     md_raw=np.squeeze(all_scores[np.where(np.abs(all_scores)==np.max(np.abs(all_scores)))])\n",
    "#     print(md_raw)\n",
    "    all_scores=averaged_df.loc[[2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012], (target, model, 'nlp', 'Rolling')]-averaged_df.loc[2002, (target, model, 'nlp', 'Rolling')]\n",
    "    md_nlp=np.min(all_scores)\n",
    "#     all_scores=np.asarray(all_scores)\n",
    "#     md_nlp=np.squeeze(all_scores[np.where(np.abs(all_scores)==np.max(np.abs(all_scores)))])\n",
    "#     print(md_nlp)\n",
    "    all_scores=averaged_df.loc[[2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012], (target, model, 'Level2', 'Rolling')]-averaged_df.loc[2002, (target, model, 'Level2', 'Rolling')]\n",
    "    md_clin=np.min(all_scores)\n",
    "#     all_scores=np.asarray(all_scores)\n",
    "#     md_clin=np.squeeze(all_scores[np.where(np.abs(all_scores)==np.max(np.abs(all_scores)))])\n",
    "#     print(md_clin)\n",
    "    \n",
    "    print('{} & ${:.2f} \\\\pm {:.2f}$ & ${:.2f} \\\\pm {:.2f}$ & $\\\\boldsymbol{{{:.2f} \\\\pm {:.2f}}}$ & & ${:.2f}$ & ${:.2f}$ & ${:.2f}$ \\\\\\\\'.format(model.upper(), m_raw, s_raw, m_nlp, s_nlp, m_clin, s_clin, md_raw, md_nlp, md_clin))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Plots for length of stay > 3 days</h2>\n",
    "<a id=los></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for ticks\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter, AutoMinorLocator)\n",
    "minorLocator = MultipleLocator(1)\n",
    "\n",
    "target='los_3'\n",
    "\n",
    "fig=plt.figure(dpi=200)\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    len(TRAIN_STYLES), len(MODEL_TYPES), sharex=True, sharey=True, figsize=(20, 7), dpi=160, facecolor='w', edgecolor='k'\n",
    ")\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.1)\n",
    "\n",
    "orig_ticks=axs[0,0].get_yticks()\n",
    "print(orig_ticks)\n",
    "for i in range(len(TRAIN_STYLES)):\n",
    "    for j in range(len(MODEL_TYPES)):\n",
    "        axs[i,j].set_yticks([])\n",
    "\n",
    "for i, train_style in enumerate(TRAIN_STYLES):\n",
    "    for j, representation in enumerate(REPRESENTATIONS):\n",
    "#         for modeltype in ['rf', 'lr', 'svm', 'rbf-svm', 'knn', 'mlp', 'lstm', 'gru']:\n",
    "        colours=iter(['#648FFF',  '#DC267F', '#FE6100', '#FFB000', '#785EF0']) #IBM\n",
    "        for modeltype in MODEL_TYPES:\n",
    "            years=averaged_df.index.tolist()\n",
    "            years=[year for year in years if year not in {2001, 2002}]\n",
    "#             if i==0:\n",
    "#                 axs[i,j].set_title(representation)\n",
    "#             if j==0:\n",
    "#                 ylabel=train_style\n",
    "#                 if ylabel=='GH':\n",
    "#                     ylabel='2001-2002'\n",
    "#                 axs[i,j].set_ylabel(ylabel)\n",
    "#             axs[i,j].set_yticks(orig_ticks)\n",
    "            axs[i,j].set_yticks([0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "            axs[i,j].set_xticks([2003, 2005, 2007, 2009, 2011, 2013])\n",
    "#             if i == 2: axs[i,j].set_xticklabels([2003, 2005, 2007, 2009, 2011, 2013])\n",
    "            axs[i,j].set_xlim(2002.5, 2013.5)\n",
    "            axs[i,j].set_ylim([0.5,1.0])\n",
    "            axs[i,j].xaxis.set_minor_locator(minorLocator)\n",
    "            axs[i,j].axvspan(2008, 2009, facecolor='#d1d1d1', alpha=0.6, label=\"CareVue → MetaVision\")\n",
    "            c=next(colours)\n",
    "            try:\n",
    "                means=averaged_df.loc[years, (target, modeltype, representation, train_style)].values\n",
    "                err=ste_df.loc[years, (target, modeltype, representation, train_style)].values\n",
    "#                 print(years, means, err)\n",
    "                gh_plot=axs[i,j].errorbar(\n",
    "                    [x + 0.5 for x in years],means,err, label=NAMES[modeltype], linewidth=4, color=c,\n",
    "                )\n",
    "                \n",
    "            except:\n",
    "                pass\n",
    "#             # Save just the portion _inside_ the second axis's boundaries\n",
    "            save_name=os.path.abspath(\"los_3-{}-{}.png\".format(train_style, representation))\n",
    "            bbox = axs[i,j].get_tightbbox(fig.canvas.get_renderer())\n",
    "            fig.savefig(save_name,bbox_inches=bbox.transformed(fig.dpi_scale_trans.inverted()))\n",
    "            if (i==0)&(j==0):\n",
    "                handles=0\n",
    "\n",
    "#             try:\n",
    "#                 lineheight=averaged_static_df.loc[0, (modeltype, representation, 'AUC')]\n",
    "#                 axs[j,i].axhline(linewidth=4, color='r')\n",
    "        \n",
    "\n",
    "for i, train_style in enumerate(TRAIN_STYLES):\n",
    "    for j, representation in enumerate(REPRESENTATIONS):\n",
    "        axs[i,j].set_yticks([0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "        axs[i,j].yaxis.grid() # horizontal lines\n",
    "        \n",
    "#         if j == 0: axs[i,j].set_yticks([0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "#         else: axs[i, j].set_yticks([])\n",
    "#         if i != 2: axs[i, j].set_xticks([])\n",
    "            \n",
    "        axs[i,j].tick_params(labelsize=13)\n",
    "        if i==0: axs[i,j].set_title(NAMES[representation], fontsize=22)\n",
    "        if j==0: axs[i,j].set_ylabel(NAMES[train_style], fontsize=22)\n",
    "    \n",
    "handles, labels = axs[1,1].get_legend_handles_labels()\n",
    "ax = fig.add_axes([0.8, 0.9, 0.1, 0.45])\n",
    "ax.set_axis_off()\n",
    "\n",
    "fig.legend(handles[3:], labels[3:], loc=\"upper right\", borderaxespad=0.2, bbox_to_anchor=(0.81,1.27), fontsize=22)\n",
    "fig.suptitle('LOS AUROC vs. Time, by Model & Representation', fontsize=24)\n",
    "\n",
    "\n",
    "plt.savefig('los_3-results.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Results by gender and ethnicity</h2>\n",
    "<a id=sensitive></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "## by gender\n",
    "\n",
    "\n",
    "\n",
    "def query_gender(train_type, modeltype, representation, target, text_files):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    level='itemid'\n",
    "    if representation=='Level2':\n",
    "        level='Level2'\n",
    "    if representation=='nlp':\n",
    "        level='nlp'\n",
    "    if representation in ['itemid', 'Level2', 'nlp']:\n",
    "        representation='raw'\n",
    "    all_seeds_list=[]\n",
    "    for random_seed in range(5):\n",
    "        filename=\"AUC_{}-style_{}_{}_Simple_{}_seed-{}_test-size-02_target={}.txt\".format(train_type, modeltype.upper(), representation, level, str(random_seed), str(target))\n",
    "        for text_file in text_files:\n",
    "            if filename in text_file:\n",
    "#                 print(text_file)\n",
    "                filename=text_file\n",
    "                break\n",
    "#         print(filename)\n",
    "        with open(text_file, 'r') as f:\n",
    "            lines=f.readlines()\n",
    "#         print(lines)\n",
    "        gender_list=[]\n",
    "        for year in range(2001, 2013):\n",
    "            for line in lines:\n",
    "                line=line.replace(\" \", \"\")\n",
    "                try:\n",
    "#                     int(line.split(',')[1])\n",
    "                except:\n",
    "#                     print(line)\n",
    "                    continue\n",
    "                if int(line.split(',')[1])==year:\n",
    "                    # see if it is the gender line\n",
    "                    if 'gender'==line.split(',')[2]:\n",
    "                        gender_index=np.asarray([float(item) for item in line.split('<')[1].split('>')[0].split(',')])\n",
    "                    elif 'y_pred_prob'==line.split(',')[2]:\n",
    "                        pred_prob=np.asarray([float(item) for item in line.split('<')[1].split('>')[0].split(',')])\n",
    "                    elif 'label'==line.split(',')[2]:\n",
    "                        label=np.asarray([float(item) for item in line.split('<')[1].split('>')[0].split(',')])\n",
    "                    else:\n",
    "                        continue\n",
    "            try:\n",
    "                auc_0=roc_auc_score(label[np.where(gender_index==0)], pred_prob[np.where(gender_index==0)])\n",
    "                auc_1=roc_auc_score(label[np.where(gender_index==1)], pred_prob[np.where(gender_index==1)])\n",
    "                gender_list.append((year, auc_0, auc_1))\n",
    "            except:\n",
    "                # it doesn't include this year\n",
    "                pass\n",
    "\n",
    "        all_seeds_list.append(gender_list)\n",
    "\n",
    "    # print(all_seeds_list)\n",
    "\n",
    "\n",
    "    mean_0=np.zeros((len(all_seeds_list[0])))\n",
    "    ste_0=np.zeros((len(all_seeds_list[0])))\n",
    "    mean_1=np.zeros((len(all_seeds_list[0])))\n",
    "    ste_1=np.zeros((len(all_seeds_list[0])))\n",
    "    years=np.zeros((len(all_seeds_list[0])))\n",
    "    for i in range(len(all_seeds_list[0])):\n",
    "        try:\n",
    "            years[i]=[item[i][0] for item in all_seeds_list][0]+1 #because we test on future\n",
    "        except:\n",
    "#             print(years, all_seeds_list)\n",
    "            pass\n",
    "        mean_0[i]=np.mean([item[i][1] for item in all_seeds_list])\n",
    "        ste_0[i]=np.std([item[i][1] for item in all_seeds_list])/np.sqrt(5)\n",
    "        mean_1[i]=np.mean([item[i][2] for item in all_seeds_list])\n",
    "        ste_1[i]=np.std([item[i][2] for item in all_seeds_list])/np.sqrt(5)\n",
    "\n",
    "    return years, mean_0, ste_0, mean_1, ste_1\n",
    "    \n",
    "\n",
    "    \n",
    "def query_ethnicity(train_type, modeltype, representation, target, text_files):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    global this_is_the_line\n",
    "    level='itemid'\n",
    "    if representation=='Level2':\n",
    "        level='Level2'\n",
    "    if representation=='nlp':\n",
    "        level='nlp'\n",
    "    if representation in ['itemid', 'Level2', 'nlp']:\n",
    "        representation='raw'\n",
    "    all_seeds_list=[]\n",
    "    for random_seed in range(5):\n",
    "        filename=\"AUC_{}-style_{}_{}_Simple_{}_seed-{}_test-size-02_target={}.txt\".format(train_type, modeltype.upper(), representation, level, str(random_seed), str(target))\n",
    "        for text_file in text_files:\n",
    "            if filename in text_file:\n",
    "#                 print(text_file)\n",
    "                filename=text_file\n",
    "                break\n",
    "        with open(text_file, 'r') as f:\n",
    "            lines=f.readlines()\n",
    "#         print(lines)\n",
    "        gender_list=[]\n",
    "#         print(text_file)\n",
    "        for year in range(2002, 2013):\n",
    "            for line in lines:\n",
    "                line=line.replace(\" \", \"\").strip()\n",
    "                if int(line.split(',')[1])==year:\n",
    "                    # see if it is the gender line\n",
    "                    if 'ethnicity'==line.split(',')[2]:\n",
    "#                         print('eth')\n",
    "                        ethnicity_index=np.asarray([float(item) for item in line.split('<')[1].split('>')[0].split(',')])\n",
    "#                         print(len(ethnicity_index))\n",
    "                    elif 'y_pred_prob'==line.split(',')[2]:\n",
    "#                         print('y_pred_prob')\n",
    "                        pred_prob=np.asarray([float(item) for item in line.split('<')[1].split('>')[0].split(',')])\n",
    "#                         print(len(pred_prob))\n",
    "                    elif 'label'==line.split(',')[2]:\n",
    "#                         print('label')\n",
    "#                         print(line.count(','))\n",
    "                        \n",
    "                        label=np.asarray([float(item) for item in line.split('<')[1].split('>')[0].split(',')])\n",
    "#                         if int(line.split(',')[1])==2002:\n",
    "#                             if (modeltype=='grud')&((level=='nlp')&(train_type=='Rolling_limited')):\n",
    "#                                 print(line[:20])\n",
    "#                                 print(line[-10:])\n",
    "#                                 this_is_the_line=label\n",
    "#                                 print(\"this is the line\")\n",
    "#                         print(len(label))\n",
    "#                         print(len(line))\n",
    "                    else:\n",
    "                        pass\n",
    "#                 if ('label' in line[:20])&(str(year) in line[:20]):\n",
    "#                     print(len(line))\n",
    "#                 if filename == 'utils/AUC_Rolling_limited-style_GRUD_raw_Simple_nlp_seed-0_test-size-02_target=mort_icu.txt':\n",
    "#                     print(line[:20])\n",
    "\n",
    "            \n",
    "            aucs=[]\n",
    "            for ethnicity in range(5):\n",
    "                try:\n",
    "                    len(np.unique(label[np.where(ethnicity_index==ethnicity)]))\n",
    "                except:\n",
    "#                     print(len(label), len(ethnicity_index))\n",
    "                    pass\n",
    "                \n",
    "                if len(np.unique(label[np.where(ethnicity_index==ethnicity)]))==1:\n",
    "                    aucs.append(0.5)\n",
    "                else:\n",
    "                    aucs.append(roc_auc_score(label[np.where(ethnicity_index==ethnicity)], pred_prob[np.where(ethnicity_index==ethnicity)]))\n",
    "\n",
    "            gender_list.append((year, *aucs))\n",
    "            \n",
    "            try:\n",
    "                \n",
    "                aucs=[]\n",
    "                for ethnicity in range(5):\n",
    "                   \n",
    "                    if len(np.unique(label[np.where(ethnicity_index==ethnicity)]))==1:\n",
    "                        aucs.append(0.5)\n",
    "                    else:\n",
    "                        aucs.append(roc_auc_score(label[np.where(ethnicity_index==ethnicity)], pred_prob[np.where(ethnicity_index==ethnicity)]))\n",
    "\n",
    "                gender_list.append((year, *aucs))\n",
    "            except:\n",
    "                # it doesn't include this year\n",
    "                pass\n",
    "\n",
    "        all_seeds_list.append(gender_list)\n",
    "\n",
    "    # print(all_seeds_list)\n",
    "    \n",
    "    means=np.zeros((5, len(all_seeds_list[0])))\n",
    "    stes=np.zeros((5, len(all_seeds_list[0])))\n",
    "    years=np.zeros((len(all_seeds_list[0])))\n",
    "\n",
    "    for i in range(len(all_seeds_list[0])):\n",
    "        years[i]=[item[i][0] for item in all_seeds_list][0]+1 #because we test on future\n",
    "        for j in range(5):\n",
    "            means[j, i]=np.mean([item[i][1+j] for item in all_seeds_list])\n",
    "            stes[j, i]=np.std([item[i][1+j] for item in all_seeds_list])/np.sqrt(5)\n",
    "#             counts[j,i]=len([item[i][1+j] for item in all_seeds_list])\n",
    "       \n",
    "\n",
    "    return years, means, stes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltype='grud'\n",
    "representation='raw'\n",
    "level='itemid'\n",
    "target='mort_icu'\n",
    "train_type='Rolling'\n",
    "\n",
    "genders=['Male', 'Female']\n",
    "\n",
    "fig=plt.figure()\n",
    "\n",
    "fig, axs = plt.subplots(2,3, sharex=True, figsize=(15, 6), facecolor='w', edgecolor='k')\n",
    "\n",
    "orig_ticks=axs[0,0].get_yticks()\n",
    "print(orig_ticks)\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        axs[i,j].set_yticks([])\n",
    "\n",
    "\n",
    "for i, train_style in enumerate(['GH', 'Rolling']):\n",
    "    for j, representation in enumerate(['itemid', 'nlp', 'Level2']):\n",
    "        years=averaged_df.index.tolist()\n",
    "        years=[year for year in years if ((year not in [2001, 2002])&(train_style=='GH'))|(train_style!='GH') ]\n",
    "#         if i==0:\n",
    "#             axs[i,j].set_title(representation)\n",
    "#         if j==0:\n",
    "#             ylabel=train_style\n",
    "#             if ylabel=='GH':\n",
    "#                 ylabel='2001-2002'\n",
    "#             axs[i,j].set_ylabel(ylabel)\n",
    "        axs[i,j].set_yticks([0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "        axs[i,j].set_xticks([2003, 2005, 2007, 2009, 2011, 2013])\n",
    "#             if i == 2: axs[i,j].set_xticklabels([2003, 2005, 2007, 2009, 2011, 2013])\n",
    "        axs[i,j].set_xlim(2002.5, 2013.5)\n",
    "        axs[i,j].set_ylim([0.5,1.0])\n",
    "        axs[i,j].xaxis.set_minor_locator(minorLocator)\n",
    "        axs[i,j].axvspan(2008, 2009, facecolor='#d1d1d1', alpha=0.6, label=\"CareVue → MetaVision\")\n",
    "#         axs[i,j].set_yticks([0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "#         axs[i,j].set_ylim([0.5,1.0])\n",
    "#         axs[i,j].xaxis.set_minor_locator(minorLocator)\n",
    "        \n",
    "        years, mean_0, ste_0, mean_1, ste_1=query_gender(train_style, modeltype, representation, target, text_files)\n",
    "        colours=iter(['#648FFF',  '#DC267F', '#FE6100', '#FFB000', '#785EF0']) #IBM\n",
    "        gh_plot=axs[i,j].errorbar(years,mean_0,ste_0, label='Male', linewidth=4, color='#648FFF') #female?\n",
    "        gh_plot=axs[i,j].errorbar(years,mean_1,ste_1, label='Female', linewidth=4, color='#FFB000', linestyle='--') #male?\n",
    "        \n",
    "        # Save just the portion _inside_ the second axis's boundaries\n",
    "        save_name=os.path.abspath(\"gender-{}-{}-{}.png\".format(modeltype, train_style, representation))\n",
    "        bbox = axs[i,j].get_tightbbox(fig.canvas.get_renderer())\n",
    "        fig.savefig(save_name,bbox_inches=bbox.transformed(fig.dpi_scale_trans.inverted()))\n",
    "\n",
    "\n",
    "\n",
    "for i, train_style in enumerate(['GH', 'Rolling']):\n",
    "    for j, representation in enumerate(['itemid', 'nlp', 'Level2']):\n",
    "        axs[i,j].set_yticks([0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "        if i==0:\n",
    "                axs[i,j].set_title(NAMES[representation], fontsize=22)\n",
    "        if j==0:\n",
    "            ylabel=train_style\n",
    "#             if ylabel=='GH':\n",
    "#                 ylabel='2001-2002'\n",
    "            axs[i,j].set_ylabel(NAMES[ylabel], fontsize=22)\n",
    "            \n",
    "\n",
    "handles, labels = axs[1,1].get_legend_handles_labels()\n",
    "# fig.legend(handles, labels, loc='upper right')\n",
    "# lgd=axs[0,2].legend(handles, labels, loc=\"upper right\", borderaxespad=0.2, bbox_to_anchor=(0.81,1.95), fontsize=22)\n",
    "lgd=axs[0,2].legend(handles, labels, loc=\"right\", borderaxespad=0.2, bbox_to_anchor=(1.81,0), fontsize=12) # bbox_to_anchor=(0.81,1.95),\n",
    "# plt.tight_layout()\n",
    "plt.savefig('gender.png', bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# print(\"rolling limited style has an alignment issue with the years (accidentally indexed them wrong)\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltype='grud'\n",
    "representation='raw'\n",
    "level='itemid'\n",
    "target='mort_icu'\n",
    "\n",
    "ethnicities=['Asian', 'Black', 'Hispanic', 'White', 'Other']\n",
    "years, means, stes=query_ethnicity(train_style, modeltype, representation, target, text_files)\n",
    "\n",
    "\n",
    "fig=plt.figure()\n",
    "\n",
    "fig, axs = plt.subplots(2,3, sharex=True, figsize=(15, 6), facecolor='w', edgecolor='k')\n",
    "\n",
    "for i, train_style in enumerate(['GH', 'Rolling']):\n",
    "    for j, representation in enumerate(['itemid', 'nlp', 'Level2']):\n",
    "        if (modeltype=='grud') and representation=='pca':\n",
    "            continue\n",
    "        years=averaged_df.index.tolist()\n",
    "        years=[year for year in years if ((year not in [2001, 2002])&(train_style=='GH'))|(train_style!='GH') ]\n",
    "        \n",
    "        axs[i,j].set_yticks([0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "        axs[i,j].set_xticks([2003, 2005, 2007, 2009, 2011, 2013])\n",
    "        axs[i,j].set_xlim(2002.5, 2013.5)\n",
    "        axs[i,j].set_ylim([0.5,1.0])\n",
    "        axs[i,j].xaxis.set_minor_locator(minorLocator)\n",
    "        axs[i,j].axvspan(2008, 2009, facecolor='#d1d1d1', alpha=0.6, label=\"CareVue → MetaVision\")\n",
    "        \n",
    "        colours=iter(['#648FFF',  '#DC267F', '#FE6100', '#FFB000', '#785EF0']) #IBM\n",
    "        years, means, stes=query_ethnicity(train_style, modeltype, representation, target, text_files)\n",
    "        for index in range(len(means)):\n",
    "            linewidths=[1,2,1,4,4]\n",
    "            linestyles=['-', '--', '--', '-', '-']\n",
    "            gh_plot=axs[i,j].errorbar(years,means[index,:].ravel(),stes[index,:].ravel(), label=ethnicities[index], color=next(colours), linewidth=linewidths[index], linestyle=linestyles[index]) #female?\n",
    "\n",
    "#         try:\n",
    "#             years, means, stes=query_ethnicity(train_style, modeltype, representation, target, text_files)\n",
    "#             for index in range(len(means)):\n",
    "#                 gh_plot=axs[i,j].errorbar(years,means[index,:].ravel(),stes[index,:].ravel(), label=ethnicities[index], color=next(colours)) #female?\n",
    "#         except:\n",
    "#             continue\n",
    "\n",
    "            \n",
    "for i, train_style in enumerate(['GH', 'Rolling']):\n",
    "    for j, representation in enumerate(['itemid', 'nlp', 'Level2']):\n",
    "        axs[i,j].set_yticks([0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "        if i==0:\n",
    "                axs[i,j].set_title(NAMES[representation], fontsize=22)\n",
    "        if j==0:\n",
    "            ylabel=train_style\n",
    "            axs[i,j].set_ylabel(NAMES[ylabel], fontsize=22)\n",
    "            \n",
    "handles, labels = axs[1,1].get_legend_handles_labels()\n",
    "# fig.legend(handles, labels, loc='upper right')\n",
    "lgd=axs[0,2].legend(handles, labels, loc=\"right\", borderaxespad=0.2, bbox_to_anchor=(1.81,0), fontsize=12) # bbox_to_anchor=(0.81,1.95),\n",
    "plt.savefig('ethnicities.png', bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "plt.show()\n",
    "            \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "idx=pd.IndexSlice\n",
    "a=glob.glob('utils/AUC_*.txt')\n",
    "a=[f for f in a if not('no_years' in f)]\n",
    "a=[f for f in a if any([model in f for model in ['LSTM', 'LR', 'RF', 'GRUD']])]\n",
    "a=[f for f in a if not('umap' in f)]\n",
    "a=[f for f in a if not('autoencoder' in f)]\n",
    "print(len(a))\n",
    "\n",
    "iterables = [[],[0, 1, 2, 3, 4],[*list(range(2001, 2013))]]\n",
    "\n",
    "index=pd.MultiIndex.from_product(iterables, names=['subject_id','seed', 'year'])\n",
    "        \n",
    "df_patient_specific=pd.DataFrame(np.nan, columns=df.columns, index=index)\n",
    "\n",
    "display(df_patient_specific.head())\n",
    "\n",
    "modeltypes=['RF', 'LR', 'LSTM', 'GRUD']\n",
    "train_types=['GH', 'Rolling', 'Rolling_limited']\n",
    "representations=['pca', 'nlp', 'Level2', 'itemid'] # pca must precede itemid\n",
    "for tfile in tqdm_notebook(a):\n",
    "    target='mort_icu' if 'mort_icu' in tfile else 'los_3'\n",
    "    modeltype=[m for m in modeltypes if m in tfile][0]\n",
    "    train_type=[m for m in train_types if m in tfile][0]\n",
    "    representation=[m for m in representations if m in tfile][0]\n",
    "    seed=[m for m in range(5) if 'seed-'+str(m) in tfile][0]\n",
    "#     print(tfile)\n",
    "    with open(tfile, 'r') as f:\n",
    "        lines=f.readlines()\n",
    "    for year in range(2002, 2013):\n",
    "        print(year)\n",
    "        value_dict={'ethnicity':[], 'subject':[], 'y_pred_prob':[], 'gender':[], 'label':[]}\n",
    "        for line in lines:\n",
    "            line=line.strip()\n",
    "            if str(year) not in line[:20]:\n",
    "                continue\n",
    "            for k in value_dict.keys():\n",
    "                if k in line[:25]:\n",
    "                    substring=line.split('<')[1].split('>')[0]\n",
    "                    substring=substring.replace('False', '0').replace('True', '1')\n",
    "                    if k=='y_pred_prob':\n",
    "                        value_dict[k]=[float(s) for s in substring.split(',')]\n",
    "                    else:\n",
    "                        value_dict[k]=[int(float(s)) for s in substring.split(',')]\n",
    "                        \n",
    "                        \n",
    "        if len(value_dict['label'])==0:\n",
    "#             if year>2002:\n",
    "#                 print(value_dict['label'])\n",
    "            continue\n",
    "        print(year, *[k+': '+str(len(item)) for k, item in value_dict.items()])\n",
    "        if len(value_dict['label'])==len(value_dict['y_pred_prob']):\n",
    "            print(len(value_dict['label']), len(value_dict['subject']))\n",
    "            if len(value_dict['label'])==len(value_dict['subject']):\n",
    "                df_patient_specific.loc[idx[value_dict['subject'], year, seed], idx[target, modeltype.lower(), representation, train_type, 'label']]=value_dict['label']\n",
    "                df_patient_specific.loc[idx[value_dict['subject'], year, seed], idx[target, modeltype.lower(), representation, train_type, 'y_pred_prob']]=value_dict['y_pred_prob']\n",
    "                continue               \n",
    "\n",
    "                \n",
    "# display(df_patient_specific.loc[:, idx[:, 'grud', 'Level2', :, 'AUC']].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ethnicity frequencies\n",
    "counts_dict={'asian': [5, 23, 34, 31, 50, 60, 58, 69, 53, 55, 63, 42], 'black':[48, 102, 116, 134, 142, 160, 170, 162, 150, 177, 191, 127],'hispanic':[7, 25, 45, 38, 48, 62, 73, 90, 70, 71, 89, 55],'white':[319, 937, 1203, 1236, 1323, 1434, 1645, 1691, 1612, 1568, 1622, 945],'other':[217, 520, 465, 353, 279, 215, 235, 136, 180, 303, 268, 276]}\n",
    "fig, axs = plt.subplots(1,5, sharex=True, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    " \n",
    "cmap = plt.get_cmap(\"tab10\")\n",
    "cmap = ['#648FFF',  '#DC267F', '#FE6100', '#FFB000', '#785EF0'] #IBM\n",
    "\n",
    "\n",
    "for j, eth in enumerate(ethnicities):\n",
    "#     axs[3,j].set_title(ethnicities[j])\n",
    "    axs[j].set_ylim([0,1700])\n",
    "    axs[j].set_yticks([0, 750, 1500])\n",
    "    axs[j].set_yticklabels([0, 750, 1500], rotation=90)\n",
    "#     axs[j].set_xlim(xlim)\n",
    "    axs[j].set_xlim(2002.5, 2013.5)\n",
    "    axs[j].set_title(eth, fontsize=22)\n",
    "    years=list(range(2001, 2013))\n",
    "    vals=counts_dict[eth.lower()]\n",
    "    axs[j].bar(years,vals, color=cmap[j])\n",
    "axs[0].set_ylabel(\"Number of Patients\", fontsize=16) \n",
    "        \n",
    "        \n",
    "\n",
    "# handles, labels = axs[1,1].get_legend_handles_labels()\n",
    "# fig.legend(handles, labels, loc='right', fontsize=22)\n",
    "plt.savefig('ethnicities_freq.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "cmap = ['#648FFF',  '#DC267F', '#FE6100', '#FFB000', '#785EF0']\n",
    "custom_lines = [Line2D([0], [0], color=cmap[i], label=ethnicities[i], lw=4) for i in range(5)]\n",
    "legend_elements = [Line2D([0], [0], color=cmap[i], lw=4, label=ethnicities[i]) for i in range(5)]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "lines = ax.plot(data)\n",
    "ax.legend(handles=legend_elements, loc='center', fontsize=22)\n",
    "# ax.get_xaxis().set_visible(False)\n",
    "# ax.get_yaxis().set_visible(False)\n",
    "ax.axis('off')\n",
    "plt.savefig('ethnicities_freq_legend.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the outcomes for each column\n",
    "# Connect to the database\n",
    "user = 'postgres'\n",
    "host = '/var/run/postgresql'\n",
    "dbname = 'mimic'\n",
    "schema = 'mimiciii'\n",
    "\n",
    "con = psycopg2.connect(dbname=dbname, host='/var/run/postgresql')\n",
    "\n",
    "cur = con.cursor()\n",
    "cur.execute('SET search_path to {}'.format(schema))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sql query into a dataframe\n",
    "# query=\"SELECT SUBJECT_ID,HADM_ID, ADMITTIME, DISCHTIME, DEATHTIME  FROM ADMISSIONS;\"\n",
    "query=\"SELECT *  FROM ADMISSIONS;\"\n",
    "outcomes_df=psql.read_sql_query(query, con)\n",
    "\n",
    "print(len(outcomes_df['subject_id'].values), len(set(outcomes_df['subject_id'].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sql query into a dataframe\n",
    "# query=\"SELECT SUBJECT_ID,HADM_ID, ADMITTIME, DISCHTIME, DEATHTIME  FROM ADMISSIONS;\"\n",
    "query=\"SELECT *  FROM ADMISSIONS;\"\n",
    "outcomes_df=psql.read_sql_query(query, con)\n",
    "\n",
    "print(len(outcomes_df['subject_id'].values), len(set(outcomes_df['subject_id'].values)))\n",
    "\n",
    "\n",
    "if 'subject_id' in outcomes_df.columns.tolist():\n",
    "    outcomes_df.set_index(['subject_id', 'hadm_id'], inplace=True)\n",
    "\n",
    "\n",
    "indexing_df=pd.read_csv('subject_hadm.csv')\n",
    "indexing_df.set_index(['subject_id', 'hadm_id'], inplace=True)\n",
    "\n",
    "\n",
    "outcomes_df=outcomes_df.loc[indexing_df.index,:]\n",
    "outcomes_df.index=outcomes_df.index.droplevel('hadm_id')\n",
    "\n",
    "\n",
    "outcomes_df['insurance']=pd.Categorical(outcomes_df['insurance'])\n",
    "\n",
    "dfDummies=pd.get_dummies(outcomes_df['insurance'], prefix='categorical')\n",
    "insurance_df = pd.concat([outcomes_df['insurance'], dfDummies], axis=1)\n",
    "\n",
    "print(insurance_df.columns.tolist())\n",
    "print(insurance_df.loc[:, insurance_df.columns != 'insurance'].head(5))\n",
    "\n",
    "def query_insurance(train_type, modeltype, representation, insurance_df, text_files):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    level='itemid'\n",
    "    if representation=='Level2':\n",
    "        level='Level2'\n",
    "    if representation=='nlp':\n",
    "        level='nlp'\n",
    "    if representation in ['itemid', 'Level2', 'nlp']:\n",
    "        representation='raw'\n",
    "    all_seeds_list=[]\n",
    "    for random_seed in range(5):\n",
    "        filename=\"AUC_{}-style_{}_{}_Simple_{}_seed-{}_test-size-02_target={}.txt\".format(train_type, modeltype.upper(), representation, level, str(random_seed), str(target))\n",
    "        for text_file in text_files:\n",
    "            if filename in text_file:\n",
    "#                 print(text_file)\n",
    "                filename=text_file\n",
    "                break\n",
    "#         print(filename)\n",
    "        with open(text_file, 'r') as f:\n",
    "            lines=f.readlines()\n",
    "#         if 'AUC_Rolling-style_GRUD_raw_Simple_itemid_seed-0_test-size-02_target=mort_icu.txt' in filename:\n",
    "#             print(lines)\n",
    "        try:\n",
    "            assert np.any(['subject' in line for line in lines])\n",
    "        except AssertionError:\n",
    "#             print(\" no subject\")\n",
    "            continue\n",
    "        gender_list=[]\n",
    "        for year in range(2001, 2013):\n",
    "            for line in lines:\n",
    "                line=line.replace(\" \", \"\")\n",
    "                if int(line.split(',')[1])==year:\n",
    "                    # see if it is the gender line\n",
    "                    if 'subject'==line.split(',')[2]:\n",
    "                        subject_index=np.asarray([float(item) for item in line.split('<')[1].split('>')[0].split(',')])\n",
    "                    elif 'y_pred_prob'==line.split(',')[2]:\n",
    "                        pred_prob=np.asarray([float(item) for item in line.split('<')[1].split('>')[0].split(',')])\n",
    "                    elif 'label'==line.split(',')[2]:\n",
    "                        label=np.asarray([float(item) for item in line.split('<')[1].split('>')[0].split(',')])\n",
    "                    else:\n",
    "                        continue\n",
    "                        \n",
    "            try:\n",
    "                aucs=[]\n",
    "                for ind,insur in enumerate(insurance_df.loc[:, insurance_df.columns != 'insurance'].columns.tolist()):\n",
    "                    if len(np.unique(insurance_df.loc[subject_index, insur].values))==1:\n",
    "                        #get the insurance type per subject_index\n",
    "                        aucs.append(0.5)\n",
    "                    else:\n",
    "#                         print(insur)\n",
    "#                         print(len(label), len(subject_index))\n",
    "#                         print(len(label[np.where(insurance_df.loc[subject_index, insur].values==1)]))\n",
    "                        try:\n",
    "                            aucs.append(roc_auc_score(label[np.where(insurance_df.loc[subject_index, insur].values==1)], pred_prob[np.where(insurance_df.loc[subject_index, insur].values==1)]))\n",
    "                        except:\n",
    "                            aucs.append(0.5)\n",
    "\n",
    "                gender_list.append((year, *aucs))\n",
    "            except:\n",
    "                # it doesn't include this year\n",
    "                pass\n",
    "\n",
    "            \n",
    "\n",
    "        all_seeds_list.append(gender_list) #list(list(tuple())) [seed,years, groups]\n",
    "\n",
    "    # print(all_seeds_list)\n",
    "    \n",
    "    try:\n",
    "        all_seeds_list[0]\n",
    "    except:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    \n",
    "    means=np.zeros((5, len(all_seeds_list[0])))\n",
    "    stes=np.zeros((5, len(all_seeds_list[0])))\n",
    "    years=np.zeros((len(all_seeds_list[0])))\n",
    "\n",
    "    for i in range(len(all_seeds_list[0])):\n",
    "        # i indicates the year\n",
    "        years[i]=[item[i][0] for item in all_seeds_list][0]+1 #because we test on future\n",
    "        for j in range(5):\n",
    "            # j indicates the group (ie insurance type)\n",
    "            means[j, i]=np.mean([item[i][1+j] for item in all_seeds_list])\n",
    "            stes[j, i]=np.std([item[i][1+j] for item in all_seeds_list])/np.sqrt(5)\n",
    "#             counts[j,i]=len([item[i][1+j] for item in all_seeds_list])\n",
    "       \n",
    "\n",
    "    return years, means, stes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltype='grud'\n",
    "level='itemid'\n",
    "target='mort_icu'\n",
    "\n",
    "\n",
    "\n",
    "print(modeltype)\n",
    "# print(insurance_df.head(5))\n",
    "fig=plt.figure()\n",
    "\n",
    "fig, axs = plt.subplots(2,3, sharex=True, figsize=(15, 6), facecolor='w', edgecolor='k')\n",
    "\n",
    "for i, train_style in enumerate(['GH', 'Rolling']):\n",
    "    for j, representation in enumerate(['itemid', 'nlp', 'Level2']):\n",
    "        years=averaged_df.index.tolist()\n",
    "        years=[year for year in years if ((year not in [2001, 2002])&(train_style=='GH'))|(train_style!='GH') ]\n",
    "\n",
    "        axs[i,j].set_yticks([0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "        axs[i,j].set_xticks([2003, 2005, 2007, 2009, 2011, 2013])\n",
    "        axs[i,j].set_xlim(2002.5, 2013.5)\n",
    "        axs[i,j].set_ylim([0.5,1.0])\n",
    "        axs[i,j].xaxis.set_minor_locator(minorLocator)\n",
    "        axs[i,j].axvspan(2008, 2009, facecolor='#d1d1d1', alpha=0.6, label=\"CareVue → MetaVision\")\n",
    "        \n",
    "        \n",
    "#         years, means, stes=query_insurance(train_style, modeltype, representation, insurance_df, text_files)\n",
    "#         for index in range(len(means)):\n",
    "#             gh_plot=axs[i,j].errorbar(years,means[index,:].ravel(),stes[index,:].ravel(), label=insurance_df.loc[:, insurance_df.columns != 'insurance'].columns.tolist()[index].replace(\"categorical_\", \"\")) #female?\n",
    "        try:\n",
    "            years, means, stes=query_insurance(train_style, modeltype, representation, insurance_df, text_files)\n",
    "            cmap = iter(['#648FFF',  '#DC267F', '#FE6100', '#FFB000', '#785EF0'])\n",
    "            for index in range(len(means)):\n",
    "                linewidths=[1,2,4,4,1]\n",
    "                linestyles=['-', '--', '-', '-', '--']\n",
    "                gh_plot=axs[i,j].errorbar(years,means[index,:].ravel(),stes[index,:].ravel(), label=insurance_df.loc[:, insurance_df.columns != 'insurance'].columns.tolist()[index].replace(\"categorical_\", \"\"), color=next(cmap), linewidth=linewidths[index], linestyle=linestyles[index]) #female?\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "            \n",
    "for i, train_style in enumerate(['GH', 'Rolling']):\n",
    "    for j, representation in enumerate(['itemid', 'nlp', 'Level2']):\n",
    "        axs[i,j].set_yticks([0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "        if i==0:\n",
    "                axs[i,j].set_title(NAMES[representation], fontsize=22)\n",
    "        if j==0:\n",
    "            ylabel=train_style\n",
    "#             if ylabel=='GH':\n",
    "#                 ylabel='2001-2002'\n",
    "            axs[i,j].set_ylabel(NAMES[ylabel], fontsize=22)\n",
    "\n",
    "\n",
    "handles, labels = axs[1,1].get_legend_handles_labels()\n",
    "# fig.legend(handles, labels, loc='upper right', fontsize=22)\n",
    "lgd=axs[0,2].legend(handles, labels, loc=\"right\", borderaxespad=0.2, bbox_to_anchor=(1.81,0), fontsize=12) # bbox_to_anchor=(0.81,1.95),\n",
    "plt.savefig('insurance.png', bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insurance_frequencies\n",
    "counts_dict={'categorical_Government':[12, 28, 55, 47, 68, 72, 43, 58, 52, 57, 87, 60], 'categorical_Medicaid':[46, 110, 127, 114, 129, 136, 172, 197, 190, 179, 192, 130], 'categorical_Medicare':[331, 913, 1008, 979, 1020, 1040, 1225, 1144, 1194, 1196, 1278, 802], 'categorical_Private':[205, 535, 649, 621, 605, 663, 700, 725, 608, 721, 654, 436], 'categorical_Self Pay':[2, 21, 24, 31, 20, 20, 41, 24, 21, 21, 22, 17]}\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1,5, sharex=True, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    " \n",
    "cmap = plt.get_cmap(\"tab10\")\n",
    "cmap = ['#648FFF',  '#DC267F', '#FE6100', '#FFB000', '#785EF0']\n",
    "\n",
    "insurances=['categorical_Government', 'categorical_Medicaid', 'categorical_Medicare', 'categorical_Private', 'categorical_Self Pay']\n",
    "\n",
    "years=list(range(2001, 2013))\n",
    "for j, insur in enumerate(insurances):\n",
    "#     axs[3,j].set_title(ethnicities[j])\n",
    "    axs[j].set_ylim([0,1500])\n",
    "    axs[j].set_yticks([0, 500, 1000, 1500])\n",
    "    axs[j].set_yticklabels([0, 500, 1000, 1500], rotation=90)\n",
    "    axs[j].set_xlim(2002.5, 2013.5)\n",
    "    axs[j].set_title(insur.replace(\"categorical_\",\"\"), fontsize=22)\n",
    "    years=list(range(2001, 2013))\n",
    "    vals=counts_dict[insur]\n",
    "    axs[j].bar(years,vals, color=cmap[j])\n",
    "axs[0].set_ylabel(\"Number of Patients\", fontsize=16) \n",
    "    \n",
    "plt.savefig('insurance_freqs.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "cmap = ['#648FFF',  '#DC267F', '#FE6100', '#FFB000', '#785EF0']\n",
    "# custom_lines = [Line2D([0], [0], color=cmap[i], label=insurances[i], lw=4) for i in range(5)]\n",
    "legend_elements = [Line2D([0], [0], color=cmap[i], lw=4, label=insurances[i].replace(\"categorical_\",\"\")) for i in range(5)]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "lines = ax.plot(data)\n",
    "ax.legend(handles=legend_elements, loc='center', fontsize=22)\n",
    "# ax.get_xaxis().set_visible(False)\n",
    "# ax.get_yaxis().set_visible(False)\n",
    "ax.axis('off')\n",
    "plt.savefig('insurance_freq_legend.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Plots for training paradigm <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 1       # the width of the bars: can also be len(x) sequence\n",
    "\n",
    "fig=plt.figure()\n",
    "ax = fig.add_subplot(141)\n",
    "plt.ylabel('EMR data sorted by year')\n",
    "\n",
    "['test', 'train_end', 'train_start']\n",
    "\n",
    "ind=np.arange(2003,2013)\n",
    "\n",
    "#naive\n",
    "test_end=np.asarray([2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012])+1\n",
    "test_start=test_end-1\n",
    "train_end=np.asarray([2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003])\n",
    "train_start=np.asarray([2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001])\n",
    "rectsa = ax.bar(ind-width, test_end-test_start, width, bottom=test_start,  color='k')\n",
    "rects2 = ax.bar(ind-width, test_start-train_end, width, bottom=train_end, color='w')\n",
    "train_first = ax.bar(ind-width, train_end-train_start, width, bottom=train_start, color='k', alpha=0.3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_start=np.arange(2002, 2012)\n",
    "train_end=train_start+1\n",
    "test_start=train_end\n",
    "test_end=test_start+1\n",
    "\n",
    "ax = fig.add_subplot(142)\n",
    "ax.yaxis.set_visible(False) \n",
    "\n",
    "# prev year only\n",
    "rectsb = ax.bar(ind, test_end-test_start, width, bottom=test_start,  color='k')\n",
    "# rects2 = ax.bar(ind+width, test_start-train_end, width, bottom=train_end, color='w')\n",
    "train_prev = ax.bar(ind, train_end-train_start, width, bottom=train_start, color='k', alpha=0.3)\n",
    "rects4 = ax.bar(ind, train_start-2001, width, bottom=2001-0.5, color='w')\n",
    "\n",
    "\n",
    "train_start=np.asarray([2001]*10)\n",
    "train_end=np.arange(2003, 2013)\n",
    "test_start=train_end\n",
    "test_end=test_start+1\n",
    "ax = fig.add_subplot(143)\n",
    "ax.yaxis.set_visible(False) \n",
    "# prev year only\n",
    "rectsc = ax.bar(ind+width, test_end-test_start, width, bottom=test_start,  color='k')\n",
    "# rects2 = ax.bar(ind+width, test_start-train_end, width, bottom=train_end, color='w')\n",
    "train_all = ax.bar(ind+width, train_end-train_start, width, bottom=2001, color='k', alpha=0.3)\n",
    "rects4 = ax.bar(ind+width, train_start-2001, width, bottom=2001-0.5, color='w')\n",
    "\n",
    "\n",
    "\n",
    "samp = np.linspace(2001, 2013, num=200)\n",
    "print(len(samp))\n",
    "assignment=np.random.choice([0,1],p=[0.2, 0.8], size=len(samp))\n",
    "bottom=2001\n",
    "ax = fig.add_subplot(144)\n",
    "ax.yaxis.set_visible(False) \n",
    "ax.xaxis.set_visible(False) \n",
    "for i in range(len(samp)-1):\n",
    "    if assignment[i+1]:\n",
    "        train_ex = ax.bar(2013, samp[i+1]-samp[i], width*2, bottom=samp[i], color='k',alpha=0.3)\n",
    "    else:\n",
    "        test_ex = ax.bar(2013, samp[i+1]-samp[i], width*2, bottom=samp[i], color='k')\n",
    "lgd =ax.legend([rectsa, train_first],[\"Test data\",\"Train data\"],bbox_to_anchor=(1.05, 1.0))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ax.legend()\n",
    "\n",
    "ax.set_ylim([2001, 2013])\n",
    "plt.xlabel('Test year')\n",
    "fig.text(0.5, 0, 'Test year', ha='center')\n",
    "plt.ylabel('EMR data sorted by year')\n",
    "plt.savefig('training_paradigm_2.png', bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
